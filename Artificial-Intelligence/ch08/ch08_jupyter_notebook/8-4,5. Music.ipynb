{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 8-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n",
    "\n",
    "# \"작은 별\" 악보를 ABC 표기로 표현\n",
    "little_star=\"tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2\"\n",
    "# music21.converter.parse(little_star).show('mid') # 스피커로 연주를 들려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 8, 2) (34, 2)\n",
      "[[1 4]\n",
      " [1 4]\n",
      " [5 4]\n",
      " [5 4]\n",
      " [6 4]\n",
      " [6 4]\n",
      " [5 2]\n",
      " [4 4]] [4 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 계이름과 숫자를 상호 변환하는 표(딕셔너리 자료구조를 사용함)\n",
    "note2num={'c':1,'d':2,'e':3,'f':4,'g':5,'a':6,'b':7}\n",
    "num2note={1:'c',2:'d',3:'e',4:'f',5:'g',6:'a',7:'b'}\n",
    "\n",
    "# ABC 표기를 시계열 데이터로 변환\n",
    "def abc2timeseries(s):\n",
    "    notes=s.split(' ')[2:]\n",
    "    seq=[]\n",
    "    for i in notes:\n",
    "        seq.append([note2num[i[0]],int(i[1])])\n",
    "    return seq\n",
    "\n",
    "# 시계열 데이터를 ABC 표기로 변환\n",
    "def timeseries2abc(t):\n",
    "    s='tinynotation: 4/4'\n",
    "    for i in t:\n",
    "        s=s+' '+num2note[i[0]]+str(i[1])\n",
    "    return s\n",
    "\n",
    "# 원핫 코드로 변환하는 표\n",
    "onehot=[[1,2],[2,2],[3,2],[4,2],[5,2],[6,2],[7,2],[1,4],[2,4],[3,4],[4,4],[5,4],[6,4],[7,4],[1,8],[2,8],[3,8],[4,8],[5,8],[6,8],[7,8]]\n",
    "\n",
    "# 레이블을 원핫 코드로 변환\n",
    "def to_onehot(l):\n",
    "    t=[]\n",
    "    for i in range(len(l)):\n",
    "        a=np.zeros(len(onehot))\n",
    "        a[onehot.index(list(l[i]))]=1.0\n",
    "        t.append(a)\n",
    "    return np.array(t)\n",
    "\n",
    "# 시계열 데이터를 훈련 집합으로 자름\n",
    "def seq2dataset(seq,window,horizon):\n",
    "    X=[]; Y=[]\n",
    "    for i in range(len(seq)-(window+horizon)+1):\n",
    "        x=seq[i:(i+window)]\n",
    "        y=(seq[i+window+horizon-1])\n",
    "        X.append(x); Y.append(y)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "w=8 # 윈도우 크기\n",
    "h=1 # 수평선 계수\n",
    "\n",
    "seq=abc2timeseries(little_star)\n",
    "X,Y=seq2dataset(seq,w,h)\n",
    "print(X.shape,Y.shape)\n",
    "print(X[0],Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 - 1s - loss: 2.9393 - accuracy: 0.0588 - 765ms/epoch - 23ms/step\n",
      "Epoch 2/200\n",
      "34/34 - 0s - loss: 2.2818 - accuracy: 0.2059 - 195ms/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "34/34 - 0s - loss: 2.1162 - accuracy: 0.1765 - 194ms/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "34/34 - 0s - loss: 1.9979 - accuracy: 0.2647 - 189ms/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "34/34 - 0s - loss: 1.8892 - accuracy: 0.2647 - 193ms/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "34/34 - 0s - loss: 1.8101 - accuracy: 0.3529 - 191ms/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "34/34 - 0s - loss: 1.7066 - accuracy: 0.3235 - 192ms/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "34/34 - 0s - loss: 1.7291 - accuracy: 0.3529 - 193ms/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "34/34 - 0s - loss: 1.5436 - accuracy: 0.3824 - 195ms/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "34/34 - 0s - loss: 1.5488 - accuracy: 0.3529 - 194ms/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "34/34 - 0s - loss: 1.4301 - accuracy: 0.4706 - 194ms/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "34/34 - 0s - loss: 1.3828 - accuracy: 0.5000 - 191ms/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "34/34 - 0s - loss: 1.2945 - accuracy: 0.5294 - 192ms/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "34/34 - 0s - loss: 1.1961 - accuracy: 0.5294 - 193ms/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "34/34 - 0s - loss: 1.2861 - accuracy: 0.5000 - 194ms/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "34/34 - 0s - loss: 1.2025 - accuracy: 0.5882 - 195ms/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "34/34 - 0s - loss: 1.1932 - accuracy: 0.5000 - 197ms/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "34/34 - 0s - loss: 0.9763 - accuracy: 0.5882 - 195ms/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "34/34 - 0s - loss: 1.0548 - accuracy: 0.5882 - 195ms/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "34/34 - 0s - loss: 0.9602 - accuracy: 0.6471 - 195ms/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "34/34 - 0s - loss: 1.2125 - accuracy: 0.4706 - 196ms/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "34/34 - 0s - loss: 0.9883 - accuracy: 0.5294 - 194ms/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "34/34 - 0s - loss: 0.9994 - accuracy: 0.5882 - 198ms/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "34/34 - 0s - loss: 0.9778 - accuracy: 0.5294 - 193ms/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "34/34 - 0s - loss: 0.8078 - accuracy: 0.6765 - 196ms/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "34/34 - 0s - loss: 0.7226 - accuracy: 0.7353 - 196ms/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "34/34 - 0s - loss: 0.6825 - accuracy: 0.7941 - 197ms/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "34/34 - 0s - loss: 0.5566 - accuracy: 0.7941 - 193ms/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "34/34 - 0s - loss: 0.6363 - accuracy: 0.8235 - 193ms/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "34/34 - 0s - loss: 0.8786 - accuracy: 0.7059 - 193ms/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "34/34 - 0s - loss: 0.7406 - accuracy: 0.7941 - 194ms/epoch - 6ms/step\n",
      "Epoch 32/200\n",
      "34/34 - 0s - loss: 0.5408 - accuracy: 0.7941 - 193ms/epoch - 6ms/step\n",
      "Epoch 33/200\n",
      "34/34 - 0s - loss: 0.5959 - accuracy: 0.7059 - 193ms/epoch - 6ms/step\n",
      "Epoch 34/200\n",
      "34/34 - 0s - loss: 0.5737 - accuracy: 0.7941 - 195ms/epoch - 6ms/step\n",
      "Epoch 35/200\n",
      "34/34 - 0s - loss: 0.6692 - accuracy: 0.6471 - 195ms/epoch - 6ms/step\n",
      "Epoch 36/200\n",
      "34/34 - 0s - loss: 0.5635 - accuracy: 0.7353 - 196ms/epoch - 6ms/step\n",
      "Epoch 37/200\n",
      "34/34 - 0s - loss: 0.5465 - accuracy: 0.7647 - 195ms/epoch - 6ms/step\n",
      "Epoch 38/200\n",
      "34/34 - 0s - loss: 0.4644 - accuracy: 0.8235 - 175ms/epoch - 5ms/step\n",
      "Epoch 39/200\n",
      "34/34 - 0s - loss: 0.4807 - accuracy: 0.7647 - 193ms/epoch - 6ms/step\n",
      "Epoch 40/200\n",
      "34/34 - 0s - loss: 0.3565 - accuracy: 0.8529 - 191ms/epoch - 6ms/step\n",
      "Epoch 41/200\n",
      "34/34 - 0s - loss: 0.4966 - accuracy: 0.8235 - 194ms/epoch - 6ms/step\n",
      "Epoch 42/200\n",
      "34/34 - 0s - loss: 0.4168 - accuracy: 0.8235 - 197ms/epoch - 6ms/step\n",
      "Epoch 43/200\n",
      "34/34 - 0s - loss: 0.4183 - accuracy: 0.8235 - 196ms/epoch - 6ms/step\n",
      "Epoch 44/200\n",
      "34/34 - 0s - loss: 0.4447 - accuracy: 0.7941 - 196ms/epoch - 6ms/step\n",
      "Epoch 45/200\n",
      "34/34 - 0s - loss: 0.4144 - accuracy: 0.8235 - 193ms/epoch - 6ms/step\n",
      "Epoch 46/200\n",
      "34/34 - 0s - loss: 0.3741 - accuracy: 0.8824 - 195ms/epoch - 6ms/step\n",
      "Epoch 47/200\n",
      "34/34 - 0s - loss: 1.3959 - accuracy: 0.6176 - 196ms/epoch - 6ms/step\n",
      "Epoch 48/200\n",
      "34/34 - 0s - loss: 0.8794 - accuracy: 0.7353 - 194ms/epoch - 6ms/step\n",
      "Epoch 49/200\n",
      "34/34 - 0s - loss: 0.5489 - accuracy: 0.7941 - 195ms/epoch - 6ms/step\n",
      "Epoch 50/200\n",
      "34/34 - 0s - loss: 0.5230 - accuracy: 0.7647 - 192ms/epoch - 6ms/step\n",
      "Epoch 51/200\n",
      "34/34 - 0s - loss: 0.3788 - accuracy: 0.8529 - 193ms/epoch - 6ms/step\n",
      "Epoch 52/200\n",
      "34/34 - 0s - loss: 0.2377 - accuracy: 0.9412 - 173ms/epoch - 5ms/step\n",
      "Epoch 53/200\n",
      "34/34 - 0s - loss: 0.3062 - accuracy: 0.8824 - 190ms/epoch - 6ms/step\n",
      "Epoch 54/200\n",
      "34/34 - 0s - loss: 0.4514 - accuracy: 0.7941 - 194ms/epoch - 6ms/step\n",
      "Epoch 55/200\n",
      "34/34 - 0s - loss: 0.2387 - accuracy: 0.8824 - 194ms/epoch - 6ms/step\n",
      "Epoch 56/200\n",
      "34/34 - 0s - loss: 0.1561 - accuracy: 0.9118 - 194ms/epoch - 6ms/step\n",
      "Epoch 57/200\n",
      "34/34 - 0s - loss: 0.1684 - accuracy: 0.9118 - 194ms/epoch - 6ms/step\n",
      "Epoch 58/200\n",
      "34/34 - 0s - loss: 0.2183 - accuracy: 0.8529 - 187ms/epoch - 5ms/step\n",
      "Epoch 59/200\n",
      "34/34 - 0s - loss: 0.3251 - accuracy: 0.8235 - 193ms/epoch - 6ms/step\n",
      "Epoch 60/200\n",
      "34/34 - 0s - loss: 0.1834 - accuracy: 0.8824 - 192ms/epoch - 6ms/step\n",
      "Epoch 61/200\n",
      "34/34 - 0s - loss: 0.1644 - accuracy: 0.9412 - 193ms/epoch - 6ms/step\n",
      "Epoch 62/200\n",
      "34/34 - 0s - loss: 0.1714 - accuracy: 0.9412 - 191ms/epoch - 6ms/step\n",
      "Epoch 63/200\n",
      "34/34 - 0s - loss: 0.1474 - accuracy: 0.9118 - 192ms/epoch - 6ms/step\n",
      "Epoch 64/200\n",
      "34/34 - 0s - loss: 0.0746 - accuracy: 0.9706 - 195ms/epoch - 6ms/step\n",
      "Epoch 65/200\n",
      "34/34 - 0s - loss: 0.1318 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 66/200\n",
      "34/34 - 0s - loss: 0.1252 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 67/200\n",
      "34/34 - 0s - loss: 0.2083 - accuracy: 0.9118 - 184ms/epoch - 5ms/step\n",
      "Epoch 68/200\n",
      "34/34 - 0s - loss: 1.0439 - accuracy: 0.7353 - 190ms/epoch - 6ms/step\n",
      "Epoch 69/200\n",
      "34/34 - 0s - loss: 0.7583 - accuracy: 0.8824 - 195ms/epoch - 6ms/step\n",
      "Epoch 70/200\n",
      "34/34 - 0s - loss: 0.4327 - accuracy: 0.8824 - 196ms/epoch - 6ms/step\n",
      "Epoch 71/200\n",
      "34/34 - 0s - loss: 0.2578 - accuracy: 0.9412 - 196ms/epoch - 6ms/step\n",
      "Epoch 72/200\n",
      "34/34 - 0s - loss: 0.2162 - accuracy: 0.9412 - 195ms/epoch - 6ms/step\n",
      "Epoch 73/200\n",
      "34/34 - 0s - loss: 0.3835 - accuracy: 0.7647 - 196ms/epoch - 6ms/step\n",
      "Epoch 74/200\n",
      "34/34 - 0s - loss: 1.0558 - accuracy: 0.6471 - 197ms/epoch - 6ms/step\n",
      "Epoch 75/200\n",
      "34/34 - 0s - loss: 0.7169 - accuracy: 0.7353 - 200ms/epoch - 6ms/step\n",
      "Epoch 76/200\n",
      "34/34 - 0s - loss: 0.3617 - accuracy: 0.9118 - 196ms/epoch - 6ms/step\n",
      "Epoch 77/200\n",
      "34/34 - 0s - loss: 0.1703 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 78/200\n",
      "34/34 - 0s - loss: 0.1079 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 79/200\n",
      "34/34 - 0s - loss: 0.0883 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 80/200\n",
      "34/34 - 0s - loss: 0.0966 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 81/200\n",
      "34/34 - 0s - loss: 0.3484 - accuracy: 0.8235 - 191ms/epoch - 6ms/step\n",
      "Epoch 82/200\n",
      "34/34 - 0s - loss: 0.2557 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 83/200\n",
      "34/34 - 0s - loss: 0.1345 - accuracy: 0.9412 - 191ms/epoch - 6ms/step\n",
      "Epoch 84/200\n",
      "34/34 - 0s - loss: 0.0994 - accuracy: 0.9706 - 191ms/epoch - 6ms/step\n",
      "Epoch 85/200\n",
      "34/34 - 0s - loss: 0.0981 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 86/200\n",
      "34/34 - 0s - loss: 0.0872 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 87/200\n",
      "34/34 - 0s - loss: 0.0856 - accuracy: 0.9412 - 192ms/epoch - 6ms/step\n",
      "Epoch 88/200\n",
      "34/34 - 0s - loss: 0.0543 - accuracy: 0.9412 - 192ms/epoch - 6ms/step\n",
      "Epoch 89/200\n",
      "34/34 - 0s - loss: 0.0536 - accuracy: 0.9706 - 191ms/epoch - 6ms/step\n",
      "Epoch 90/200\n",
      "34/34 - 0s - loss: 0.0641 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 91/200\n",
      "34/34 - 0s - loss: 0.0539 - accuracy: 0.9706 - 195ms/epoch - 6ms/step\n",
      "Epoch 92/200\n",
      "34/34 - 0s - loss: 0.0619 - accuracy: 0.9706 - 195ms/epoch - 6ms/step\n",
      "Epoch 93/200\n",
      "34/34 - 0s - loss: 0.0953 - accuracy: 0.9412 - 195ms/epoch - 6ms/step\n",
      "Epoch 94/200\n",
      "34/34 - 0s - loss: 0.0589 - accuracy: 0.9706 - 191ms/epoch - 6ms/step\n",
      "Epoch 95/200\n",
      "34/34 - 0s - loss: 0.0511 - accuracy: 0.9706 - 189ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "34/34 - 0s - loss: 0.0457 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 97/200\n",
      "34/34 - 0s - loss: 0.0595 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 98/200\n",
      "34/34 - 0s - loss: 0.0545 - accuracy: 0.9706 - 195ms/epoch - 6ms/step\n",
      "Epoch 99/200\n",
      "34/34 - 0s - loss: 0.2234 - accuracy: 0.9118 - 193ms/epoch - 6ms/step\n",
      "Epoch 100/200\n",
      "34/34 - 0s - loss: 0.2300 - accuracy: 0.9412 - 197ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "34/34 - 0s - loss: 0.1504 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 102/200\n",
      "34/34 - 0s - loss: 0.0673 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 103/200\n",
      "34/34 - 0s - loss: 0.0832 - accuracy: 0.9706 - 190ms/epoch - 6ms/step\n",
      "Epoch 104/200\n",
      "34/34 - 0s - loss: 0.0737 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 105/200\n",
      "34/34 - 0s - loss: 0.0624 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 106/200\n",
      "34/34 - 0s - loss: 0.0702 - accuracy: 0.9412 - 196ms/epoch - 6ms/step\n",
      "Epoch 107/200\n",
      "34/34 - 0s - loss: 0.0512 - accuracy: 0.9706 - 195ms/epoch - 6ms/step\n",
      "Epoch 108/200\n",
      "34/34 - 0s - loss: 0.0434 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 109/200\n",
      "34/34 - 0s - loss: 0.0369 - accuracy: 0.9706 - 188ms/epoch - 6ms/step\n",
      "Epoch 110/200\n",
      "34/34 - 0s - loss: 0.0479 - accuracy: 0.9706 - 191ms/epoch - 6ms/step\n",
      "Epoch 111/200\n",
      "34/34 - 0s - loss: 0.0587 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "34/34 - 0s - loss: 0.0838 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 113/200\n",
      "34/34 - 0s - loss: 0.0447 - accuracy: 1.0000 - 196ms/epoch - 6ms/step\n",
      "Epoch 114/200\n",
      "34/34 - 0s - loss: 0.0589 - accuracy: 0.9412 - 196ms/epoch - 6ms/step\n",
      "Epoch 115/200\n",
      "34/34 - 0s - loss: 0.0489 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 116/200\n",
      "34/34 - 0s - loss: 0.0471 - accuracy: 0.9706 - 198ms/epoch - 6ms/step\n",
      "Epoch 117/200\n",
      "34/34 - 0s - loss: 0.0513 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 118/200\n",
      "34/34 - 0s - loss: 0.0594 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 119/200\n",
      "34/34 - 0s - loss: 0.2496 - accuracy: 0.8824 - 195ms/epoch - 6ms/step\n",
      "Epoch 120/200\n",
      "34/34 - 0s - loss: 0.8964 - accuracy: 0.7941 - 192ms/epoch - 6ms/step\n",
      "Epoch 121/200\n",
      "34/34 - 0s - loss: 0.7858 - accuracy: 0.6765 - 193ms/epoch - 6ms/step\n",
      "Epoch 122/200\n",
      "34/34 - 0s - loss: 0.3318 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 123/200\n",
      "34/34 - 0s - loss: 0.2189 - accuracy: 0.9118 - 188ms/epoch - 6ms/step\n",
      "Epoch 124/200\n",
      "34/34 - 0s - loss: 0.1568 - accuracy: 0.9412 - 191ms/epoch - 6ms/step\n",
      "Epoch 125/200\n",
      "34/34 - 0s - loss: 0.0817 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 126/200\n",
      "34/34 - 0s - loss: 0.0915 - accuracy: 0.9412 - 195ms/epoch - 6ms/step\n",
      "Epoch 127/200\n",
      "34/34 - 0s - loss: 0.0622 - accuracy: 0.9412 - 196ms/epoch - 6ms/step\n",
      "Epoch 128/200\n",
      "34/34 - 0s - loss: 0.0435 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 129/200\n",
      "34/34 - 0s - loss: 0.0441 - accuracy: 0.9706 - 198ms/epoch - 6ms/step\n",
      "Epoch 130/200\n",
      "34/34 - 0s - loss: 0.0417 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 131/200\n",
      "34/34 - 0s - loss: 0.0497 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 132/200\n",
      "34/34 - 0s - loss: 0.0469 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 133/200\n",
      "34/34 - 0s - loss: 0.0270 - accuracy: 1.0000 - 195ms/epoch - 6ms/step\n",
      "Epoch 134/200\n",
      "34/34 - 0s - loss: 0.0824 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 135/200\n",
      "34/34 - 0s - loss: 0.0916 - accuracy: 0.9706 - 189ms/epoch - 6ms/step\n",
      "Epoch 136/200\n",
      "34/34 - 0s - loss: 0.0378 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 137/200\n",
      "34/34 - 0s - loss: 0.0369 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 138/200\n",
      "34/34 - 0s - loss: 0.0381 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 139/200\n",
      "34/34 - 0s - loss: 0.0338 - accuracy: 1.0000 - 196ms/epoch - 6ms/step\n",
      "Epoch 140/200\n",
      "34/34 - 0s - loss: 0.0225 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 141/200\n",
      "34/34 - 0s - loss: 0.0170 - accuracy: 1.0000 - 196ms/epoch - 6ms/step\n",
      "Epoch 142/200\n",
      "34/34 - 0s - loss: 0.0198 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 143/200\n",
      "34/34 - 0s - loss: 0.0202 - accuracy: 1.0000 - 192ms/epoch - 6ms/step\n",
      "Epoch 144/200\n",
      "34/34 - 0s - loss: 0.2298 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 145/200\n",
      "34/34 - 0s - loss: 4.5431 - accuracy: 0.5294 - 191ms/epoch - 6ms/step\n",
      "Epoch 146/200\n",
      "34/34 - 0s - loss: 1.7900 - accuracy: 0.5882 - 193ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "34/34 - 0s - loss: 1.3792 - accuracy: 0.5588 - 192ms/epoch - 6ms/step\n",
      "Epoch 148/200\n",
      "34/34 - 0s - loss: 0.8994 - accuracy: 0.7059 - 195ms/epoch - 6ms/step\n",
      "Epoch 149/200\n",
      "34/34 - 0s - loss: 0.6986 - accuracy: 0.7647 - 192ms/epoch - 6ms/step\n",
      "Epoch 150/200\n",
      "34/34 - 0s - loss: 0.5632 - accuracy: 0.8235 - 192ms/epoch - 6ms/step\n",
      "Epoch 151/200\n",
      "34/34 - 0s - loss: 0.3601 - accuracy: 0.9118 - 198ms/epoch - 6ms/step\n",
      "Epoch 152/200\n",
      "34/34 - 0s - loss: 0.2460 - accuracy: 0.8824 - 182ms/epoch - 5ms/step\n",
      "Epoch 153/200\n",
      "34/34 - 0s - loss: 0.1898 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "34/34 - 0s - loss: 0.7406 - accuracy: 0.8529 - 191ms/epoch - 6ms/step\n",
      "Epoch 155/200\n",
      "34/34 - 0s - loss: 0.5016 - accuracy: 0.7941 - 191ms/epoch - 6ms/step\n",
      "Epoch 156/200\n",
      "34/34 - 0s - loss: 0.2322 - accuracy: 0.9412 - 194ms/epoch - 6ms/step\n",
      "Epoch 157/200\n",
      "34/34 - 0s - loss: 0.1346 - accuracy: 0.9412 - 198ms/epoch - 6ms/step\n",
      "Epoch 158/200\n",
      "34/34 - 0s - loss: 0.1191 - accuracy: 0.9412 - 195ms/epoch - 6ms/step\n",
      "Epoch 159/200\n",
      "34/34 - 0s - loss: 0.2055 - accuracy: 0.9118 - 195ms/epoch - 6ms/step\n",
      "Epoch 160/200\n",
      "34/34 - 0s - loss: 0.0968 - accuracy: 1.0000 - 196ms/epoch - 6ms/step\n",
      "Epoch 161/200\n",
      "34/34 - 0s - loss: 0.0661 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 162/200\n",
      "34/34 - 0s - loss: 0.0465 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 163/200\n",
      "34/34 - 0s - loss: 0.0537 - accuracy: 0.9412 - 196ms/epoch - 6ms/step\n",
      "Epoch 164/200\n",
      "34/34 - 0s - loss: 0.0386 - accuracy: 1.0000 - 195ms/epoch - 6ms/step\n",
      "Epoch 165/200\n",
      "34/34 - 0s - loss: 0.0432 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 166/200\n",
      "34/34 - 0s - loss: 0.0473 - accuracy: 0.9706 - 193ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "34/34 - 0s - loss: 0.0296 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 168/200\n",
      "34/34 - 0s - loss: 0.0280 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 169/200\n",
      "34/34 - 0s - loss: 0.0331 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 170/200\n",
      "34/34 - 0s - loss: 0.0193 - accuracy: 1.0000 - 195ms/epoch - 6ms/step\n",
      "Epoch 171/200\n",
      "34/34 - 0s - loss: 0.1432 - accuracy: 0.9118 - 196ms/epoch - 6ms/step\n",
      "Epoch 172/200\n",
      "34/34 - 0s - loss: 0.2878 - accuracy: 0.8824 - 194ms/epoch - 6ms/step\n",
      "Epoch 173/200\n",
      "34/34 - 0s - loss: 0.5665 - accuracy: 0.8529 - 194ms/epoch - 6ms/step\n",
      "Epoch 174/200\n",
      "34/34 - 0s - loss: 0.1733 - accuracy: 0.9412 - 197ms/epoch - 6ms/step\n",
      "Epoch 175/200\n",
      "34/34 - 0s - loss: 0.0708 - accuracy: 0.9706 - 194ms/epoch - 6ms/step\n",
      "Epoch 176/200\n",
      "34/34 - 0s - loss: 0.0402 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 177/200\n",
      "34/34 - 0s - loss: 0.0444 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 178/200\n",
      "34/34 - 0s - loss: 0.0426 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 179/200\n",
      "34/34 - 0s - loss: 0.0404 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 180/200\n",
      "34/34 - 0s - loss: 0.0305 - accuracy: 1.0000 - 177ms/epoch - 5ms/step\n",
      "Epoch 181/200\n",
      "34/34 - 0s - loss: 0.0473 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 182/200\n",
      "34/34 - 0s - loss: 0.6430 - accuracy: 0.8529 - 197ms/epoch - 6ms/step\n",
      "Epoch 183/200\n",
      "34/34 - 0s - loss: 0.3162 - accuracy: 0.9118 - 196ms/epoch - 6ms/step\n",
      "Epoch 184/200\n",
      "34/34 - 0s - loss: 0.0952 - accuracy: 1.0000 - 195ms/epoch - 6ms/step\n",
      "Epoch 185/200\n",
      "34/34 - 0s - loss: 0.0528 - accuracy: 0.9706 - 197ms/epoch - 6ms/step\n",
      "Epoch 186/200\n",
      "34/34 - 0s - loss: 0.0498 - accuracy: 0.9706 - 196ms/epoch - 6ms/step\n",
      "Epoch 187/200\n",
      "34/34 - 0s - loss: 0.0207 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 188/200\n",
      "34/34 - 0s - loss: 0.0307 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 189/200\n",
      "34/34 - 0s - loss: 0.0355 - accuracy: 0.9706 - 192ms/epoch - 6ms/step\n",
      "Epoch 190/200\n",
      "34/34 - 0s - loss: 0.0293 - accuracy: 1.0000 - 192ms/epoch - 6ms/step\n",
      "Epoch 191/200\n",
      "34/34 - 0s - loss: 0.0258 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 192/200\n",
      "34/34 - 0s - loss: 0.0259 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 193/200\n",
      "34/34 - 0s - loss: 0.0107 - accuracy: 1.0000 - 192ms/epoch - 6ms/step\n",
      "Epoch 194/200\n",
      "34/34 - 0s - loss: 0.0099 - accuracy: 1.0000 - 184ms/epoch - 5ms/step\n",
      "Epoch 195/200\n",
      "34/34 - 0s - loss: 0.0072 - accuracy: 1.0000 - 187ms/epoch - 6ms/step\n",
      "Epoch 196/200\n",
      "34/34 - 0s - loss: 0.0055 - accuracy: 1.0000 - 193ms/epoch - 6ms/step\n",
      "Epoch 197/200\n",
      "34/34 - 0s - loss: 0.0034 - accuracy: 1.0000 - 190ms/epoch - 6ms/step\n",
      "Epoch 198/200\n",
      "34/34 - 0s - loss: 0.0029 - accuracy: 1.0000 - 191ms/epoch - 6ms/step\n",
      "Epoch 199/200\n",
      "34/34 - 0s - loss: 0.0023 - accuracy: 1.0000 - 194ms/epoch - 6ms/step\n",
      "Epoch 200/200\n",
      "34/34 - 0s - loss: 0.0026 - accuracy: 1.0000 - 192ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3f784879a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 집합 구축\n",
    "split=int(len(X)*1.0) # 100%를 훈련집합으로 사용\n",
    "x_train=X[0:split]; y_train=Y[0:split]\n",
    "y_train=to_onehot(y_train)\n",
    "\n",
    "# LSTM 모델 설계와 학습\n",
    "model=Sequential()\n",
    "model.add(LSTM(units=128,activation='relu',input_shape=x_train[0].shape))\n",
    "model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=200,batch_size=1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 4],\n",
       "        [1, 4],\n",
       "        [5, 4],\n",
       "        [5, 4],\n",
       "        [6, 4],\n",
       "        [6, 4],\n",
       "        [5, 2],\n",
       "        [4, 4]]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델로 편곡을 하는 함수(first_measure: 첫 소절, duration: 생성될 곡의 길이)\n",
    "def arranging_music(model,first_measure,duration):\n",
    "    music=first_measure\n",
    "    for i in range(duration):\n",
    "        p=model.predict(np.float32(np.expand_dims(music[-w:],axis=0)))\n",
    "        music=np.append(music,[onehot[np.argmax(p)]],axis=0)\n",
    "    return timeseries2abc(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4\n"
     ]
    }
   ],
   "source": [
    "new_song=arranging_music(model,x_train[0],50)\n",
    "\n",
    "print(new_song)\n",
    "# music21.converter.parse(new_song).show('mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4\n"
     ]
    }
   ],
   "source": [
    "new_song=arranging_music(model,x_train[0],100)\n",
    "\n",
    "print(new_song)\n",
    "# music21.converter.parse(new_song).show('mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "tinynotation: 4/4 g4 e4 e2 f4 d4 d2 c4 d4 g4 g4 a4 a4 g2 f4 e4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4\n"
     ]
    }
   ],
   "source": [
    "new_song=arranging_music(model,[[5,4],[3,4],[3,2],[4,4],[2,4],[2,2],[1,4],[2,4]],50)\n",
    "\n",
    "print(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program 8-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"작은 별\", \"봄나들이\", \"나비야 나비야\" 악보를 ABC 표기로 표현\n",
    "little_star=\"tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g4 g4 f4 f4 e4 e4 d2 g4 g4 f4 f4 e4 e4 d2 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2\"\n",
    "spring_picnic=\"tinynotation: 4/8 g8 e8 g8 e8 g8 a8 g4 e8 g8 e8 c8 d8 e8 c4 g8 e8 g8 e8 g8 a8 g4 b8 a8 g8 e8 d8 e8 c4\"\n",
    "butterfly=\"tinynotation: 2/4 g8 e8 e4 f8 d8 d4 c8 d8 e8 f8 g8 g8 g4 g8 e8 e8 e8 f8 d8 d4 c8 e8 g8 g8 e8 e8 e4 d8 d8 d8 d8 d8 e8 f4 e8 e8 e8 e8 e8 f8 g4 g8 e8 e4 f8 d8 d4 c8 e8 g8 g8 e8 e8 e4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 곡을 시계열로 변환하고 결합\n",
    "seq1=abc2timeseries(little_star)\n",
    "seq2=abc2timeseries(butterfly)\n",
    "seq3=abc2timeseries(spring_picnic)\n",
    "seq=seq1+seq2+seq3\n",
    "\n",
    "X,Y = seq2dataset(seq,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "116/116 - 1s - loss: 2.6729 - accuracy: 0.1810 - 1s/epoch - 10ms/step\n",
      "Epoch 2/200\n",
      "116/116 - 1s - loss: 2.3130 - accuracy: 0.2241 - 658ms/epoch - 6ms/step\n",
      "Epoch 3/200\n",
      "116/116 - 1s - loss: 2.2250 - accuracy: 0.2414 - 665ms/epoch - 6ms/step\n",
      "Epoch 4/200\n",
      "116/116 - 1s - loss: 2.1989 - accuracy: 0.2845 - 654ms/epoch - 6ms/step\n",
      "Epoch 5/200\n",
      "116/116 - 1s - loss: 2.1459 - accuracy: 0.2500 - 667ms/epoch - 6ms/step\n",
      "Epoch 6/200\n",
      "116/116 - 1s - loss: 2.1045 - accuracy: 0.2931 - 662ms/epoch - 6ms/step\n",
      "Epoch 7/200\n",
      "116/116 - 1s - loss: 2.0128 - accuracy: 0.3276 - 674ms/epoch - 6ms/step\n",
      "Epoch 8/200\n",
      "116/116 - 1s - loss: 1.9747 - accuracy: 0.3276 - 673ms/epoch - 6ms/step\n",
      "Epoch 9/200\n",
      "116/116 - 1s - loss: 1.9605 - accuracy: 0.3103 - 662ms/epoch - 6ms/step\n",
      "Epoch 10/200\n",
      "116/116 - 1s - loss: 1.8832 - accuracy: 0.3190 - 658ms/epoch - 6ms/step\n",
      "Epoch 11/200\n",
      "116/116 - 1s - loss: 1.8869 - accuracy: 0.3448 - 671ms/epoch - 6ms/step\n",
      "Epoch 12/200\n",
      "116/116 - 1s - loss: 1.8196 - accuracy: 0.3621 - 669ms/epoch - 6ms/step\n",
      "Epoch 13/200\n",
      "116/116 - 1s - loss: 1.7684 - accuracy: 0.3707 - 662ms/epoch - 6ms/step\n",
      "Epoch 14/200\n",
      "116/116 - 1s - loss: 1.7951 - accuracy: 0.3879 - 665ms/epoch - 6ms/step\n",
      "Epoch 15/200\n",
      "116/116 - 1s - loss: 1.6467 - accuracy: 0.3448 - 662ms/epoch - 6ms/step\n",
      "Epoch 16/200\n",
      "116/116 - 1s - loss: 1.6653 - accuracy: 0.3621 - 667ms/epoch - 6ms/step\n",
      "Epoch 17/200\n",
      "116/116 - 1s - loss: 1.6334 - accuracy: 0.3707 - 661ms/epoch - 6ms/step\n",
      "Epoch 18/200\n",
      "116/116 - 1s - loss: 1.6398 - accuracy: 0.3534 - 657ms/epoch - 6ms/step\n",
      "Epoch 19/200\n",
      "116/116 - 1s - loss: 1.5486 - accuracy: 0.3793 - 670ms/epoch - 6ms/step\n",
      "Epoch 20/200\n",
      "116/116 - 1s - loss: 1.4926 - accuracy: 0.4224 - 674ms/epoch - 6ms/step\n",
      "Epoch 21/200\n",
      "116/116 - 1s - loss: 1.4300 - accuracy: 0.4052 - 663ms/epoch - 6ms/step\n",
      "Epoch 22/200\n",
      "116/116 - 1s - loss: 1.4171 - accuracy: 0.4138 - 660ms/epoch - 6ms/step\n",
      "Epoch 23/200\n",
      "116/116 - 1s - loss: 1.3679 - accuracy: 0.4052 - 656ms/epoch - 6ms/step\n",
      "Epoch 24/200\n",
      "116/116 - 1s - loss: 1.3750 - accuracy: 0.4397 - 662ms/epoch - 6ms/step\n",
      "Epoch 25/200\n",
      "116/116 - 1s - loss: 1.3259 - accuracy: 0.4138 - 661ms/epoch - 6ms/step\n",
      "Epoch 26/200\n",
      "116/116 - 1s - loss: 1.2668 - accuracy: 0.4138 - 665ms/epoch - 6ms/step\n",
      "Epoch 27/200\n",
      "116/116 - 1s - loss: 1.3467 - accuracy: 0.4655 - 651ms/epoch - 6ms/step\n",
      "Epoch 28/200\n",
      "116/116 - 1s - loss: 1.1546 - accuracy: 0.5000 - 669ms/epoch - 6ms/step\n",
      "Epoch 29/200\n",
      "116/116 - 1s - loss: 1.1703 - accuracy: 0.5259 - 666ms/epoch - 6ms/step\n",
      "Epoch 30/200\n",
      "116/116 - 1s - loss: 1.0751 - accuracy: 0.5259 - 669ms/epoch - 6ms/step\n",
      "Epoch 31/200\n",
      "116/116 - 1s - loss: 1.0428 - accuracy: 0.6121 - 669ms/epoch - 6ms/step\n",
      "Epoch 32/200\n",
      "116/116 - 1s - loss: 1.1411 - accuracy: 0.5345 - 677ms/epoch - 6ms/step\n",
      "Epoch 33/200\n",
      "116/116 - 1s - loss: 0.9065 - accuracy: 0.6121 - 669ms/epoch - 6ms/step\n",
      "Epoch 34/200\n",
      "116/116 - 1s - loss: 0.9874 - accuracy: 0.6379 - 670ms/epoch - 6ms/step\n",
      "Epoch 35/200\n",
      "116/116 - 1s - loss: 0.8379 - accuracy: 0.6810 - 658ms/epoch - 6ms/step\n",
      "Epoch 36/200\n",
      "116/116 - 1s - loss: 0.8108 - accuracy: 0.6897 - 657ms/epoch - 6ms/step\n",
      "Epoch 37/200\n",
      "116/116 - 1s - loss: 0.7313 - accuracy: 0.7241 - 667ms/epoch - 6ms/step\n",
      "Epoch 38/200\n",
      "116/116 - 1s - loss: 0.6732 - accuracy: 0.6983 - 664ms/epoch - 6ms/step\n",
      "Epoch 39/200\n",
      "116/116 - 1s - loss: 0.7058 - accuracy: 0.6983 - 664ms/epoch - 6ms/step\n",
      "Epoch 40/200\n",
      "116/116 - 1s - loss: 0.5448 - accuracy: 0.7845 - 662ms/epoch - 6ms/step\n",
      "Epoch 41/200\n",
      "116/116 - 1s - loss: 0.6332 - accuracy: 0.8190 - 666ms/epoch - 6ms/step\n",
      "Epoch 42/200\n",
      "116/116 - 1s - loss: 0.7692 - accuracy: 0.7155 - 668ms/epoch - 6ms/step\n",
      "Epoch 43/200\n",
      "116/116 - 1s - loss: 0.5390 - accuracy: 0.7845 - 663ms/epoch - 6ms/step\n",
      "Epoch 44/200\n",
      "116/116 - 1s - loss: 0.4489 - accuracy: 0.8362 - 660ms/epoch - 6ms/step\n",
      "Epoch 45/200\n",
      "116/116 - 1s - loss: 0.5113 - accuracy: 0.8190 - 667ms/epoch - 6ms/step\n",
      "Epoch 46/200\n",
      "116/116 - 1s - loss: 0.4112 - accuracy: 0.8448 - 670ms/epoch - 6ms/step\n",
      "Epoch 47/200\n",
      "116/116 - 1s - loss: 0.3639 - accuracy: 0.8534 - 666ms/epoch - 6ms/step\n",
      "Epoch 48/200\n",
      "116/116 - 1s - loss: 0.4490 - accuracy: 0.8534 - 661ms/epoch - 6ms/step\n",
      "Epoch 49/200\n",
      "116/116 - 1s - loss: 0.4514 - accuracy: 0.8190 - 663ms/epoch - 6ms/step\n",
      "Epoch 50/200\n",
      "116/116 - 1s - loss: 0.6178 - accuracy: 0.8707 - 665ms/epoch - 6ms/step\n",
      "Epoch 51/200\n",
      "116/116 - 1s - loss: 0.4472 - accuracy: 0.8966 - 666ms/epoch - 6ms/step\n",
      "Epoch 52/200\n",
      "116/116 - 1s - loss: 0.2863 - accuracy: 0.9138 - 657ms/epoch - 6ms/step\n",
      "Epoch 53/200\n",
      "116/116 - 1s - loss: 0.2492 - accuracy: 0.9138 - 670ms/epoch - 6ms/step\n",
      "Epoch 54/200\n",
      "116/116 - 1s - loss: 0.2706 - accuracy: 0.8793 - 666ms/epoch - 6ms/step\n",
      "Epoch 55/200\n",
      "116/116 - 1s - loss: 0.1601 - accuracy: 0.9569 - 666ms/epoch - 6ms/step\n",
      "Epoch 56/200\n",
      "116/116 - 1s - loss: 0.2777 - accuracy: 0.8793 - 658ms/epoch - 6ms/step\n",
      "Epoch 57/200\n",
      "116/116 - 1s - loss: 0.5843 - accuracy: 0.7931 - 673ms/epoch - 6ms/step\n",
      "Epoch 58/200\n",
      "116/116 - 1s - loss: 0.4980 - accuracy: 0.8448 - 672ms/epoch - 6ms/step\n",
      "Epoch 59/200\n",
      "116/116 - 1s - loss: 0.2965 - accuracy: 0.8966 - 669ms/epoch - 6ms/step\n",
      "Epoch 60/200\n",
      "116/116 - 1s - loss: 0.1753 - accuracy: 0.9224 - 665ms/epoch - 6ms/step\n",
      "Epoch 61/200\n",
      "116/116 - 1s - loss: 0.1406 - accuracy: 0.9483 - 676ms/epoch - 6ms/step\n",
      "Epoch 62/200\n",
      "116/116 - 1s - loss: 0.1653 - accuracy: 0.9397 - 669ms/epoch - 6ms/step\n",
      "Epoch 63/200\n",
      "116/116 - 1s - loss: 0.1202 - accuracy: 0.9569 - 669ms/epoch - 6ms/step\n",
      "Epoch 64/200\n",
      "116/116 - 1s - loss: 0.1885 - accuracy: 0.9052 - 646ms/epoch - 6ms/step\n",
      "Epoch 65/200\n",
      "116/116 - 1s - loss: 0.1672 - accuracy: 0.9224 - 663ms/epoch - 6ms/step\n",
      "Epoch 66/200\n",
      "116/116 - 1s - loss: 0.2797 - accuracy: 0.9397 - 677ms/epoch - 6ms/step\n",
      "Epoch 67/200\n",
      "116/116 - 1s - loss: 0.3834 - accuracy: 0.8707 - 665ms/epoch - 6ms/step\n",
      "Epoch 68/200\n",
      "116/116 - 1s - loss: 0.4046 - accuracy: 0.8707 - 659ms/epoch - 6ms/step\n",
      "Epoch 69/200\n",
      "116/116 - 1s - loss: 0.2235 - accuracy: 0.9052 - 659ms/epoch - 6ms/step\n",
      "Epoch 70/200\n",
      "116/116 - 1s - loss: 0.3166 - accuracy: 0.9138 - 673ms/epoch - 6ms/step\n",
      "Epoch 71/200\n",
      "116/116 - 1s - loss: 0.1531 - accuracy: 0.9483 - 667ms/epoch - 6ms/step\n",
      "Epoch 72/200\n",
      "116/116 - 1s - loss: 0.1533 - accuracy: 0.9569 - 671ms/epoch - 6ms/step\n",
      "Epoch 73/200\n",
      "116/116 - 1s - loss: 0.1091 - accuracy: 0.9483 - 668ms/epoch - 6ms/step\n",
      "Epoch 74/200\n",
      "116/116 - 1s - loss: 0.1007 - accuracy: 0.9655 - 667ms/epoch - 6ms/step\n",
      "Epoch 75/200\n",
      "116/116 - 1s - loss: 0.1270 - accuracy: 0.9569 - 668ms/epoch - 6ms/step\n",
      "Epoch 76/200\n",
      "116/116 - 1s - loss: 0.1268 - accuracy: 0.9483 - 661ms/epoch - 6ms/step\n",
      "Epoch 77/200\n",
      "116/116 - 1s - loss: 0.1167 - accuracy: 0.9397 - 659ms/epoch - 6ms/step\n",
      "Epoch 78/200\n",
      "116/116 - 1s - loss: 0.3389 - accuracy: 0.8879 - 663ms/epoch - 6ms/step\n",
      "Epoch 79/200\n",
      "116/116 - 1s - loss: 0.1620 - accuracy: 0.9310 - 659ms/epoch - 6ms/step\n",
      "Epoch 80/200\n",
      "116/116 - 1s - loss: 0.1286 - accuracy: 0.9397 - 661ms/epoch - 6ms/step\n",
      "Epoch 81/200\n",
      "116/116 - 1s - loss: 0.1000 - accuracy: 0.9655 - 668ms/epoch - 6ms/step\n",
      "Epoch 82/200\n",
      "116/116 - 1s - loss: 0.1150 - accuracy: 0.9397 - 679ms/epoch - 6ms/step\n",
      "Epoch 83/200\n",
      "116/116 - 1s - loss: 0.1124 - accuracy: 0.9397 - 675ms/epoch - 6ms/step\n",
      "Epoch 84/200\n",
      "116/116 - 1s - loss: 0.0901 - accuracy: 0.9569 - 672ms/epoch - 6ms/step\n",
      "Epoch 85/200\n",
      "116/116 - 1s - loss: 0.0913 - accuracy: 0.9569 - 655ms/epoch - 6ms/step\n",
      "Epoch 86/200\n",
      "116/116 - 1s - loss: 0.1351 - accuracy: 0.9310 - 672ms/epoch - 6ms/step\n",
      "Epoch 87/200\n",
      "116/116 - 1s - loss: 0.1287 - accuracy: 0.9569 - 674ms/epoch - 6ms/step\n",
      "Epoch 88/200\n",
      "116/116 - 1s - loss: 0.0710 - accuracy: 0.9741 - 675ms/epoch - 6ms/step\n",
      "Epoch 89/200\n",
      "116/116 - 1s - loss: 0.0865 - accuracy: 0.9569 - 662ms/epoch - 6ms/step\n",
      "Epoch 90/200\n",
      "116/116 - 1s - loss: 0.0713 - accuracy: 0.9655 - 655ms/epoch - 6ms/step\n",
      "Epoch 91/200\n",
      "116/116 - 1s - loss: 0.0840 - accuracy: 0.9569 - 663ms/epoch - 6ms/step\n",
      "Epoch 92/200\n",
      "116/116 - 1s - loss: 0.0906 - accuracy: 0.9569 - 677ms/epoch - 6ms/step\n",
      "Epoch 93/200\n",
      "116/116 - 1s - loss: 0.0664 - accuracy: 0.9655 - 668ms/epoch - 6ms/step\n",
      "Epoch 94/200\n",
      "116/116 - 1s - loss: 0.0639 - accuracy: 0.9655 - 663ms/epoch - 6ms/step\n",
      "Epoch 95/200\n",
      "116/116 - 1s - loss: 0.0571 - accuracy: 0.9655 - 660ms/epoch - 6ms/step\n",
      "Epoch 96/200\n",
      "116/116 - 1s - loss: 0.0704 - accuracy: 0.9569 - 668ms/epoch - 6ms/step\n",
      "Epoch 97/200\n",
      "116/116 - 1s - loss: 0.0725 - accuracy: 0.9397 - 667ms/epoch - 6ms/step\n",
      "Epoch 98/200\n",
      "116/116 - 1s - loss: 0.0730 - accuracy: 0.9741 - 654ms/epoch - 6ms/step\n",
      "Epoch 99/200\n",
      "116/116 - 1s - loss: 1.0172 - accuracy: 0.7414 - 663ms/epoch - 6ms/step\n",
      "Epoch 100/200\n",
      "116/116 - 1s - loss: 0.5469 - accuracy: 0.8276 - 671ms/epoch - 6ms/step\n",
      "Epoch 101/200\n",
      "116/116 - 1s - loss: 0.3404 - accuracy: 0.8707 - 669ms/epoch - 6ms/step\n",
      "Epoch 102/200\n",
      "116/116 - 1s - loss: 0.1958 - accuracy: 0.9310 - 659ms/epoch - 6ms/step\n",
      "Epoch 103/200\n",
      "116/116 - 1s - loss: 0.2066 - accuracy: 0.9310 - 672ms/epoch - 6ms/step\n",
      "Epoch 104/200\n",
      "116/116 - 1s - loss: 0.1412 - accuracy: 0.9483 - 673ms/epoch - 6ms/step\n",
      "Epoch 105/200\n",
      "116/116 - 1s - loss: 0.0710 - accuracy: 0.9655 - 672ms/epoch - 6ms/step\n",
      "Epoch 106/200\n",
      "116/116 - 1s - loss: 0.0676 - accuracy: 0.9655 - 652ms/epoch - 6ms/step\n",
      "Epoch 107/200\n",
      "116/116 - 1s - loss: 0.0610 - accuracy: 0.9655 - 666ms/epoch - 6ms/step\n",
      "Epoch 108/200\n",
      "116/116 - 1s - loss: 0.0659 - accuracy: 0.9655 - 657ms/epoch - 6ms/step\n",
      "Epoch 109/200\n",
      "116/116 - 1s - loss: 0.0550 - accuracy: 0.9655 - 665ms/epoch - 6ms/step\n",
      "Epoch 110/200\n",
      "116/116 - 1s - loss: 0.0522 - accuracy: 0.9741 - 657ms/epoch - 6ms/step\n",
      "Epoch 111/200\n",
      "116/116 - 1s - loss: 0.0537 - accuracy: 0.9741 - 664ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "116/116 - 1s - loss: 0.0546 - accuracy: 0.9655 - 661ms/epoch - 6ms/step\n",
      "Epoch 113/200\n",
      "116/116 - 1s - loss: 0.0593 - accuracy: 0.9741 - 658ms/epoch - 6ms/step\n",
      "Epoch 114/200\n",
      "116/116 - 1s - loss: 0.0665 - accuracy: 0.9569 - 654ms/epoch - 6ms/step\n",
      "Epoch 115/200\n",
      "116/116 - 1s - loss: 0.0468 - accuracy: 0.9655 - 665ms/epoch - 6ms/step\n",
      "Epoch 116/200\n",
      "116/116 - 1s - loss: 0.0469 - accuracy: 0.9828 - 667ms/epoch - 6ms/step\n",
      "Epoch 117/200\n",
      "116/116 - 1s - loss: 0.0536 - accuracy: 0.9655 - 664ms/epoch - 6ms/step\n",
      "Epoch 118/200\n",
      "116/116 - 1s - loss: 0.2748 - accuracy: 0.8966 - 663ms/epoch - 6ms/step\n",
      "Epoch 119/200\n",
      "116/116 - 1s - loss: 0.5224 - accuracy: 0.7759 - 659ms/epoch - 6ms/step\n",
      "Epoch 120/200\n",
      "116/116 - 1s - loss: 0.4574 - accuracy: 0.8190 - 671ms/epoch - 6ms/step\n",
      "Epoch 121/200\n",
      "116/116 - 1s - loss: 0.2352 - accuracy: 0.9483 - 667ms/epoch - 6ms/step\n",
      "Epoch 122/200\n",
      "116/116 - 1s - loss: 0.0799 - accuracy: 0.9741 - 665ms/epoch - 6ms/step\n",
      "Epoch 123/200\n",
      "116/116 - 1s - loss: 0.0641 - accuracy: 0.9655 - 649ms/epoch - 6ms/step\n",
      "Epoch 124/200\n",
      "116/116 - 1s - loss: 0.0526 - accuracy: 0.9655 - 672ms/epoch - 6ms/step\n",
      "Epoch 125/200\n",
      "116/116 - 1s - loss: 0.0574 - accuracy: 0.9569 - 667ms/epoch - 6ms/step\n",
      "Epoch 126/200\n",
      "116/116 - 1s - loss: 0.0487 - accuracy: 0.9655 - 672ms/epoch - 6ms/step\n",
      "Epoch 127/200\n",
      "116/116 - 1s - loss: 0.0485 - accuracy: 0.9741 - 662ms/epoch - 6ms/step\n",
      "Epoch 128/200\n",
      "116/116 - 1s - loss: 0.0485 - accuracy: 0.9655 - 663ms/epoch - 6ms/step\n",
      "Epoch 129/200\n",
      "116/116 - 1s - loss: 0.0484 - accuracy: 0.9655 - 676ms/epoch - 6ms/step\n",
      "Epoch 130/200\n",
      "116/116 - 1s - loss: 0.0450 - accuracy: 0.9655 - 671ms/epoch - 6ms/step\n",
      "Epoch 131/200\n",
      "116/116 - 1s - loss: 0.0538 - accuracy: 0.9655 - 668ms/epoch - 6ms/step\n",
      "Epoch 132/200\n",
      "116/116 - 1s - loss: 0.0421 - accuracy: 0.9828 - 664ms/epoch - 6ms/step\n",
      "Epoch 133/200\n",
      "116/116 - 1s - loss: 0.0461 - accuracy: 0.9655 - 674ms/epoch - 6ms/step\n",
      "Epoch 134/200\n",
      "116/116 - 1s - loss: 0.0561 - accuracy: 0.9655 - 666ms/epoch - 6ms/step\n",
      "Epoch 135/200\n",
      "116/116 - 1s - loss: 0.0515 - accuracy: 0.9655 - 663ms/epoch - 6ms/step\n",
      "Epoch 136/200\n",
      "116/116 - 1s - loss: 0.0464 - accuracy: 0.9741 - 664ms/epoch - 6ms/step\n",
      "Epoch 137/200\n",
      "116/116 - 1s - loss: 0.0503 - accuracy: 0.9741 - 671ms/epoch - 6ms/step\n",
      "Epoch 138/200\n",
      "116/116 - 1s - loss: 0.0515 - accuracy: 0.9655 - 673ms/epoch - 6ms/step\n",
      "Epoch 139/200\n",
      "116/116 - 1s - loss: 0.0493 - accuracy: 0.9569 - 671ms/epoch - 6ms/step\n",
      "Epoch 140/200\n",
      "116/116 - 1s - loss: 0.0446 - accuracy: 0.9655 - 647ms/epoch - 6ms/step\n",
      "Epoch 141/200\n",
      "116/116 - 1s - loss: 0.0490 - accuracy: 0.9569 - 660ms/epoch - 6ms/step\n",
      "Epoch 142/200\n",
      "116/116 - 1s - loss: 0.0456 - accuracy: 0.9655 - 660ms/epoch - 6ms/step\n",
      "Epoch 143/200\n",
      "116/116 - 1s - loss: 0.0479 - accuracy: 0.9569 - 668ms/epoch - 6ms/step\n",
      "Epoch 144/200\n",
      "116/116 - 1s - loss: 0.0495 - accuracy: 0.9569 - 636ms/epoch - 5ms/step\n",
      "Epoch 145/200\n",
      "116/116 - 1s - loss: 0.0486 - accuracy: 0.9569 - 667ms/epoch - 6ms/step\n",
      "Epoch 146/200\n",
      "116/116 - 1s - loss: 0.0615 - accuracy: 0.9741 - 667ms/epoch - 6ms/step\n",
      "Epoch 147/200\n",
      "116/116 - 1s - loss: 0.0484 - accuracy: 0.9741 - 669ms/epoch - 6ms/step\n",
      "Epoch 148/200\n",
      "116/116 - 1s - loss: 0.0516 - accuracy: 0.9655 - 661ms/epoch - 6ms/step\n",
      "Epoch 149/200\n",
      "116/116 - 1s - loss: 0.0531 - accuracy: 0.9741 - 663ms/epoch - 6ms/step\n",
      "Epoch 150/200\n",
      "116/116 - 1s - loss: 0.0522 - accuracy: 0.9655 - 668ms/epoch - 6ms/step\n",
      "Epoch 151/200\n",
      "116/116 - 1s - loss: 0.1161 - accuracy: 0.9569 - 667ms/epoch - 6ms/step\n",
      "Epoch 152/200\n",
      "116/116 - 1s - loss: 0.4947 - accuracy: 0.8190 - 666ms/epoch - 6ms/step\n",
      "Epoch 153/200\n",
      "116/116 - 1s - loss: 0.3289 - accuracy: 0.8793 - 667ms/epoch - 6ms/step\n",
      "Epoch 154/200\n",
      "116/116 - 1s - loss: 0.0986 - accuracy: 0.9483 - 661ms/epoch - 6ms/step\n",
      "Epoch 155/200\n",
      "116/116 - 1s - loss: 0.0750 - accuracy: 0.9828 - 666ms/epoch - 6ms/step\n",
      "Epoch 156/200\n",
      "116/116 - 1s - loss: 0.0489 - accuracy: 0.9741 - 664ms/epoch - 6ms/step\n",
      "Epoch 157/200\n",
      "116/116 - 1s - loss: 0.0429 - accuracy: 0.9828 - 651ms/epoch - 6ms/step\n",
      "Epoch 158/200\n",
      "116/116 - 1s - loss: 0.0397 - accuracy: 0.9655 - 665ms/epoch - 6ms/step\n",
      "Epoch 159/200\n",
      "116/116 - 1s - loss: 0.0405 - accuracy: 0.9655 - 666ms/epoch - 6ms/step\n",
      "Epoch 160/200\n",
      "116/116 - 1s - loss: 0.0420 - accuracy: 0.9741 - 662ms/epoch - 6ms/step\n",
      "Epoch 161/200\n",
      "116/116 - 1s - loss: 0.0391 - accuracy: 0.9655 - 672ms/epoch - 6ms/step\n",
      "Epoch 162/200\n",
      "116/116 - 1s - loss: 0.0383 - accuracy: 0.9741 - 679ms/epoch - 6ms/step\n",
      "Epoch 163/200\n",
      "116/116 - 1s - loss: 0.0322 - accuracy: 0.9741 - 674ms/epoch - 6ms/step\n",
      "Epoch 164/200\n",
      "116/116 - 1s - loss: 0.0327 - accuracy: 0.9828 - 666ms/epoch - 6ms/step\n",
      "Epoch 165/200\n",
      "116/116 - 1s - loss: 0.0376 - accuracy: 0.9828 - 639ms/epoch - 6ms/step\n",
      "Epoch 166/200\n",
      "116/116 - 1s - loss: 0.0425 - accuracy: 0.9741 - 661ms/epoch - 6ms/step\n",
      "Epoch 167/200\n",
      "116/116 - 1s - loss: 0.0762 - accuracy: 0.9569 - 657ms/epoch - 6ms/step\n",
      "Epoch 168/200\n",
      "116/116 - 1s - loss: 0.0420 - accuracy: 0.9655 - 670ms/epoch - 6ms/step\n",
      "Epoch 169/200\n",
      "116/116 - 1s - loss: 0.0408 - accuracy: 0.9741 - 660ms/epoch - 6ms/step\n",
      "Epoch 170/200\n",
      "116/116 - 1s - loss: 0.0392 - accuracy: 0.9741 - 665ms/epoch - 6ms/step\n",
      "Epoch 171/200\n",
      "116/116 - 1s - loss: 0.0342 - accuracy: 0.9828 - 674ms/epoch - 6ms/step\n",
      "Epoch 172/200\n",
      "116/116 - 1s - loss: 0.0370 - accuracy: 0.9655 - 675ms/epoch - 6ms/step\n",
      "Epoch 173/200\n",
      "116/116 - 1s - loss: 0.0361 - accuracy: 0.9828 - 667ms/epoch - 6ms/step\n",
      "Epoch 174/200\n",
      "116/116 - 1s - loss: 0.0338 - accuracy: 0.9741 - 674ms/epoch - 6ms/step\n",
      "Epoch 175/200\n",
      "116/116 - 1s - loss: 0.0370 - accuracy: 0.9655 - 509ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "116/116 - 1s - loss: 0.0414 - accuracy: 0.9741 - 644ms/epoch - 6ms/step\n",
      "Epoch 177/200\n",
      "116/116 - 1s - loss: 0.0370 - accuracy: 0.9741 - 664ms/epoch - 6ms/step\n",
      "Epoch 178/200\n",
      "116/116 - 1s - loss: 0.0403 - accuracy: 0.9741 - 658ms/epoch - 6ms/step\n",
      "Epoch 179/200\n",
      "116/116 - 1s - loss: 0.0379 - accuracy: 0.9741 - 665ms/epoch - 6ms/step\n",
      "Epoch 180/200\n",
      "116/116 - 1s - loss: 0.0427 - accuracy: 0.9569 - 674ms/epoch - 6ms/step\n",
      "Epoch 181/200\n",
      "116/116 - 1s - loss: 0.0580 - accuracy: 0.9655 - 668ms/epoch - 6ms/step\n",
      "Epoch 182/200\n",
      "116/116 - 1s - loss: 0.8321 - accuracy: 0.7414 - 660ms/epoch - 6ms/step\n",
      "Epoch 183/200\n",
      "116/116 - 1s - loss: 0.5827 - accuracy: 0.8190 - 673ms/epoch - 6ms/step\n",
      "Epoch 184/200\n",
      "116/116 - 1s - loss: 0.2488 - accuracy: 0.9310 - 670ms/epoch - 6ms/step\n",
      "Epoch 185/200\n",
      "116/116 - 1s - loss: 0.3861 - accuracy: 0.8793 - 662ms/epoch - 6ms/step\n",
      "Epoch 186/200\n",
      "116/116 - 1s - loss: 0.3817 - accuracy: 0.8707 - 665ms/epoch - 6ms/step\n",
      "Epoch 187/200\n",
      "116/116 - 1s - loss: 0.1193 - accuracy: 0.9483 - 664ms/epoch - 6ms/step\n",
      "Epoch 188/200\n",
      "116/116 - 1s - loss: 0.0694 - accuracy: 0.9741 - 660ms/epoch - 6ms/step\n",
      "Epoch 189/200\n",
      "116/116 - 1s - loss: 0.0578 - accuracy: 0.9655 - 664ms/epoch - 6ms/step\n",
      "Epoch 190/200\n",
      "116/116 - 1s - loss: 0.0434 - accuracy: 0.9741 - 664ms/epoch - 6ms/step\n",
      "Epoch 191/200\n",
      "116/116 - 1s - loss: 0.0513 - accuracy: 0.9569 - 668ms/epoch - 6ms/step\n",
      "Epoch 192/200\n",
      "116/116 - 1s - loss: 0.0449 - accuracy: 0.9828 - 671ms/epoch - 6ms/step\n",
      "Epoch 193/200\n",
      "116/116 - 1s - loss: 0.0383 - accuracy: 0.9828 - 669ms/epoch - 6ms/step\n",
      "Epoch 194/200\n",
      "116/116 - 1s - loss: 0.0371 - accuracy: 0.9741 - 665ms/epoch - 6ms/step\n",
      "Epoch 195/200\n",
      "116/116 - 1s - loss: 0.0348 - accuracy: 0.9741 - 674ms/epoch - 6ms/step\n",
      "Epoch 196/200\n",
      "116/116 - 1s - loss: 0.0370 - accuracy: 0.9655 - 670ms/epoch - 6ms/step\n",
      "Epoch 197/200\n",
      "116/116 - 1s - loss: 0.0404 - accuracy: 0.9828 - 672ms/epoch - 6ms/step\n",
      "Epoch 198/200\n",
      "116/116 - 1s - loss: 0.0472 - accuracy: 0.9655 - 628ms/epoch - 5ms/step\n",
      "Epoch 199/200\n",
      "116/116 - 1s - loss: 0.0358 - accuracy: 0.9741 - 652ms/epoch - 6ms/step\n",
      "Epoch 200/200\n",
      "116/116 - 1s - loss: 0.0337 - accuracy: 0.9741 - 661ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4003cf6970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 집합 구축\n",
    "split=int(len(X)*1.0) # 100%를 훈련집합으로 사용\n",
    "x_train=X[0:split]; y_train=Y[0:split]\n",
    "y_train=to_onehot(y_train)\n",
    "\n",
    "# LSTM 모델 설계와 학습\n",
    "model2=Sequential()\n",
    "model2.add(LSTM(units=128,activation='relu',input_shape=x_train[0].shape))\n",
    "model2.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "model2.fit(x_train,y_train,epochs=200,batch_size=1,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "tinynotation: 4/4 c4 c4 g4 g4 a4 a4 g2 f4 f4 e4 e4 d4 d4 c2 g8 e8 e4 f8 d8 d4 c8 d8 e8 f8 g8 g8 g4 g8 e8 e8 e8 f8 d8 d4 c8 e8 g8 g8 e8 e8 e4 d8 d8 d8 d8 d8 e8 f4 e8 e8 e8 e8 e8 f8 g4 g8 e8 e4\n"
     ]
    }
   ],
   "source": [
    "new_song=arranging_music(model2,x_train[0],50)\n",
    "\n",
    "print(new_song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.2",
   "language": "python",
   "name": "tf2.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
